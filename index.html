<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EgoSpeak: Real-Time Speech Initiation in Egocentric Streaming Videos.">
  <meta name="keywords" content="EgoSpeak, speech initiation, egocentric video, conversation agent">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EgoSpeak Project Page</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9XGSCLPEVF"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9XGSCLPEVF');
  </script>

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <!-- Bulma and other CSS -->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <!-- Favicon (replace with your actual favicon path) -->
  <link rel="icon" href="./static/images/favicon.svg">

  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

<!-- NAVIGATION BAR -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://junhyeok.kim">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://seungjuhan.me/normlens/">
            NormLens
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
<!-- /NAVIGATION BAR -->

<!-- HERO SECTION (Title & Authors) -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <!-- Project Title -->
          <h1 class="title is-1 publication-title">EgoSpeak: Learning When to Speak <br/> for Egocentric Conversational Agents <br/> in the Wild
          </h1>

          <!-- Authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://junhyeok.kim">Junhyeok Kim</a><sup>1</sup>,</span>
            <span class="author-block">Min Soo Kim<sup>1</sup>,</span>
            <span class="author-block"><a href="https://jiwanchung.github.io/">Jiwan Chung</a><sup>1</sup>,</span>
            <span class="author-block">Jungbin Cho<sup>1</sup>,</span>
            <span class="author-block">Jisoo Kim<sup>1</sup>,</span>
            <span class="author-block">Sungwoong Kim<sup>1</sup>,</span>
            <span class="author-block">Gyeongbo Sim<sup>2</sup>,</span>
            <span class="author-block"><a href="https://mirlab.yonsei.ac.kr/">Youngjae Yu</a><sup>1</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Yonsei University</span>
            <span class="author-block"><sup>2</sup>Multimodal AI Lab., NC Research, NCSOFT Corporation</span>
          </div>

          <!-- Paper/Video/Code/Data Buttons (optional placeholders) -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link (Replace with your actual PDF link) -->
              <!-- <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->

              <!-- arXiv Link (Replace if relevant) -->
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Video Link
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->

              <!-- Code Link -->
              <span class="link-block">
                <a href="https://jun297.github.io/EgoSpeak/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code & Data</span>
                </a>
              </span>

              <!-- Data Link -->
              <!-- <span class="link-block">
                <a href="https://jun297.github.io/EgoSpeak/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span> -->

            </div>
          </div>
          <!-- /Paper/Video/Code/Data Buttons -->

        </div>
      </div>
    </div>
  </div>
</section>
<!-- /HERO SECTION -->

<!-- TEASER FIGURE -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <!-- Replace 'teaser_figure.jpg' with your actual teaser figure file -->
      <img src="./static/images/egospeak_fig1.png" alt="Teaser Figure" style="max-width: 100%;">
      <!-- <h2 class="subtitle" style="margin-top: 1em;">
        <i>EgoSpeak</i>: Learning When to Speak for Egocentric Conversational Agents in the Wild
      </h2> -->
    </div>
  </div>
</section>
<!-- /TEASER FIGURE -->

<!-- ABSTRACT SECTION -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Predicting when to initiate speech in real-world environments remains a fundamental 
            challenge for conversational agents. We introduce <b>EgoSpeak</b>, a novel framework 
            for real-time speech initiation prediction in egocentric streaming video. By modeling 
            the conversation from the speaker’s first-person viewpoint, EgoSpeak is tailored for 
            human-like interactions in which a conversational agent must continuously observe its 
            environment and dynamically decide when to talk.
          </p>
          <p>
            Our approach bridges the gap between simplified experimental setups and complex natural 
            conversations by integrating four key capabilities: (1) first-person perspective, 
            (2) RGB processing, (3) online processing, and (4) untrimmed video processing. We also 
            present YT-Conversation, a diverse collection of in-the-wild conversational videos from 
            YouTube, as a resource for large-scale pretraining. Experiments on EasyCom and Ego4D 
            demonstrate that EgoSpeak outperforms random and silence-based baselines in real time. 
            Our results also highlight the importance of multimodal input and context length in 
            effectively deciding when to speak.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- /ABSTRACT SECTION -->

<!-- (OPTIONAL) PROJECT VIDEO / DEMOS SECTION -->
<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Project Video</h2>
        <div class="publication-video">
          <iframe 
            src="https://www.youtube.com/embed/XXXXXXX?rel=0&amp;showinfo=0"
            frameborder="0"
            width="560"
            height="315"
            allow="autoplay; encrypted-media"
            allowfullscreen>
          </iframe>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- /PROJECT VIDEO SECTION -->

<!-- BIBTEX SECTION -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{kim2025egospeak,
  author = {Kim, Junhyeok and Kim, Min Soo and Chung, Jiwan and Cho, Jungbin and
            Kim, Jisoo and Kim, Sungwoong and Sim, Gyeongbo and Yu, Youngjae},
  title  = {EgoSpeak: Real-Time Speech Initiation in Egocentric Streaming Videos},
  year   = {2025},
  howpublished = {\url{https://jun297.github.io/EgoSpeak/}},
}</code></pre>
  </div>
</section> -->
<!-- /BIBTEX SECTION -->

<!-- FOOTER -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- Example icon links (GitHub, PDF) — remove if not needed -->
      <a class="icon-link" href="#" title="PDF">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/jun297" title="GitHub">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is adapted from the Nerfies project page. It is licensed under a 
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
              Creative Commons Attribution-ShareAlike 4.0 International License
            </a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!-- /FOOTER -->

</body>
</html>
